{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os, glob, random, copy, time, shutil, re\n",
    "import itertools\n",
    "# random.seed(666)\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import jellyfish\n",
    "try:\n",
    "    def hamming_distance(s1, s2):\n",
    "        if s1 == s2:\n",
    "            return 0\n",
    "        else:\n",
    "            return jellyfish.hamming_distance(s1, s2)\n",
    "    assert(hamming_distance('ABC', 'ABCD') == 1)\n",
    "except:\n",
    "    def hamming_distance(s1, s2):\n",
    "        if s1 == s2:\n",
    "            return 0\n",
    "        else:\n",
    "            return jellyfish.hamming_distance(unicode(s1), unicode(s2))\n",
    "    assert(hamming_distance('ABC', 'ABCD') == 1)\n",
    "\n",
    "import traceback\n",
    "class nostdout(object):\n",
    "    def __enter__(self):\n",
    "        self.stdout = sys.stdout\n",
    "        sys.stdout = self\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        sys.stdout = self.stdout\n",
    "        if type is not None:\n",
    "            raise\n",
    "    def write(self, x): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_naiveAA_CDF(df, verbose=True):\n",
    "    plot_dir = 'plots/naiveAA_CDF'\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "\n",
    "    def AUC(res, locus, st, cut):\n",
    "        counts = Counter(res[locus][st])\n",
    "        hd = [k for k, v in counts.items() if k <= cut]\n",
    "        c = [v for k, v in counts.items() if k <= cut]\n",
    "        hd, c = zip(*sorted(zip(hd, c)))\n",
    "        acc = [sum(c[0:i]) + c[i] for i in range(len(c))]\n",
    "        sc = sum(v for k, v in counts.items())\n",
    "        auc = sum(acc[i]*(hd[i+1]-hd[i]) for i in range(len(hd)-1)) / sc\n",
    "        return(auc)\n",
    "    \n",
    "\n",
    "    def naiveAA_plot(res, xlimit, pnam):\n",
    "    #    %matplotlib inline\n",
    "        from matplotlib.backends.backend_pdf import PdfPages\n",
    "        pp = PdfPages(pnam)\n",
    "        for locus in res:\n",
    "            fig, ax = pyplot.subplots(figsize=(14,10))\n",
    "            for st in res[locus]:\n",
    "                if st[0][0:3] == '3FT' and st[1][0:3] == '3FT':\n",
    "                    color = 'green'\n",
    "                elif st[0][0:3] == 'PLA' and st[1][0:3] == 'PLA':\n",
    "                    color = 'blue'\n",
    "                else:\n",
    "                    color = 'red'\n",
    "                auc = AUC(res, locus, st, xlimit)\n",
    "                ax = sns.distplot(\n",
    "                    res[locus][st],\n",
    "                    label='{} vs. {} AUC {:.1f}'.format(st[0], st[1], auc),\n",
    "                    color=color,\n",
    "                    kde=False,\n",
    "                    bins=list(range(0, 1000)),\n",
    "                    norm_hist=True,  # On/off to normalize y-axis\n",
    "                    hist_kws={'histtype':'step', 'cumulative':True, 'lw':3}\n",
    "                )\n",
    "                lgd = ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "                ax.set_title('Locus: {}'.format(locus))\n",
    "                ax.set_xlim(0, xlimit)\n",
    "            fig.savefig(pp, format='pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "        pp.close()\n",
    "\n",
    "\n",
    "    def compare_naive(table, trim=0, downsample=False, weighted=False):\n",
    "        df = table.copy(deep=True)\n",
    "        # Trim out small clonal families:\n",
    "        df = df[df['NumbUniqueDNA'] > trim]\n",
    "\n",
    "        row_part = dict()\n",
    "        dist_table = dict()\n",
    "\n",
    "        samples = list(set(df['sample']))\n",
    "        loci = set(df['locus'])\n",
    "\n",
    "        if downsample:\n",
    "            for locus in loci:\n",
    "                smallest = 9999999999\n",
    "                for sample in samples:\n",
    "                    print(len(df[(df['locus'] == locus) & (df['sample'] == sample)]))\n",
    "                    size = sum(np.array(df['locus'] == locus) & np.array(df['sample'] == sample))\n",
    "                    if size < smallest:\n",
    "                        smallest = size\n",
    "                print('Downsampling to:', smallest)\n",
    "                for sample in samples:\n",
    "                    # Finding the downsample:\n",
    "                    ds = df[(df['locus'] == locus) & (df['sample'] == sample)].sample(smallest, replace=False)\n",
    "                    # Dropping all columns:\n",
    "                    df = df[np.invert(np.array(((df['locus'] == locus) & (df['sample'] == sample))))]\n",
    "                    # Adding the downsample:\n",
    "                    df = df.append(ds)\n",
    "        v_grps = set(df['v_grp'])\n",
    "        d_grps = set(df['d_grp'])\n",
    "        j_grps = set(df['j_grp'])\n",
    "        vdj_len = set(df['vdj_len'])\n",
    "\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # kt = (row['locus'], row['v_grp'], row['d_grp'], row['j_grp'], row['vdj_len'])\n",
    "            kt = (row['locus'], row['v_grp'], row['d_grp'], row['j_grp'])\n",
    "            if kt not in row_part:\n",
    "                row_part[kt] = [index]\n",
    "            else:\n",
    "                row_part[kt].append(index)\n",
    "        sumstat = [len(l) for l in row_part.values()]\n",
    "        #    print('These are the number of entries in each partition:', list(map(str, sumstat)))\n",
    "\n",
    "        # res[locus][s1:s2] = [dist, 5, 2, 0,...]\n",
    "        res = dict()\n",
    "        for locus in loci:\n",
    "            res[locus] = dict()\n",
    "            for i in range(len(samples)):\n",
    "                for j in range(i+1, len(samples)):\n",
    "                    si = samples[i]\n",
    "                    sj = samples[j]\n",
    "                    res[locus][(si, sj)] = list()\n",
    "                    for kt, li in row_part.items():\n",
    "                        if locus != kt[0]:\n",
    "                            continue\n",
    "                        naivei = list(df.loc[li][df.loc[li]['sample'] == si]['naiveAA'])\n",
    "                        naivej = list(df.loc[li][df.loc[li]['sample'] == sj]['naiveAA'])\n",
    "                        if len(naivei) == 0 or len(naivej) == 0:\n",
    "                            continue\n",
    "                        hdj = [min(hamming_distance(ni, nj) for ni in naivei) for nj in naivej]\n",
    "                        hdi = [min(hamming_distance(ni, nj) for nj in naivej) for ni in naivei]\n",
    "                        if weighted is True:\n",
    "                            cf_abui = list(df.loc[li][df.loc[li]['sample'] == si]['abundance'])\n",
    "                            cf_abuj = list(df.loc[li][df.loc[li]['sample'] == sj]['abundance'])\n",
    "                            hdj = [h for h, a in zip(hdj, cf_abuj) for i in range(a)]\n",
    "                            hdi = [h for h, a in zip(hdi, cf_abui) for i in range(a)]\n",
    "                        res[locus][(si, sj)].extend(hdi)\n",
    "                        res[locus][(si, sj)].extend(hdj)\n",
    "\n",
    "        ds = '_downsampled' if downsample else ''\n",
    "        we = '_weighted' if weighted else ''\n",
    "        pnam = plot_dir + '/NaiveAA_comparison_trim{}{}{}.pdf'.format(trim, ds, we)\n",
    "        naiveAA_plot(res, 30, pnam)\n",
    "\n",
    "\n",
    "    trim_list = [0, 5]\n",
    "    downsample_list = [True, False]\n",
    "    weighted_list = [True, False]\n",
    "    combs = list(itertools.product(*[trim_list, downsample_list, weighted_list]))\n",
    "    for c in combs:\n",
    "        if verbose:\n",
    "            compare_naive(df, *c)\n",
    "        else:\n",
    "            with nostdout():\n",
    "                compare_naive(df, *c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/cf.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Placeholder for all the plotting functions:\n",
    "plot_naiveAA_CDF(df, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
